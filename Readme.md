*MixMod* is a type of neural network based on the *LSTM* family, more specifically
*GRU*. It attempts to simplify the architecture while retaining the intuitive
understanding of how it works. In certain cases it can work better than either
*LSTM* or *GRU*, and additionally keeps its memory and output separate, allowing
for richer models.

Its name is a cutesy alliteration describing roughly what its two main gate
networks do - *mix* old and new data and *mod*ify its hidden state (memory).
